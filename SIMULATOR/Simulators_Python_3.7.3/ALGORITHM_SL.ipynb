{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb1bcb68",
   "metadata": {},
   "source": [
    "# Split Learning (SL) Allocation Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd485940",
   "metadata": {},
   "source": [
    "## The algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fa4901c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reminder of what each state needs:\n",
    "# state0_SL() needs () and returns (clients, servers, paths)\n",
    "# state1_SL() needs (clients, servers, paths) and returns (paths)\n",
    "# OR (clients, servers, paths)\n",
    "# state2_SL() needs (paths) and returns (best_path)\n",
    "\n",
    "def SL_allocation_alg(event_processors, event_links, event_clients):\n",
    "    \n",
    "    # Set global variables so all states run correctly\n",
    "    global processors\n",
    "    processors = event_processors\n",
    "    global links\n",
    "    links = event_links\n",
    "    global state\n",
    "    state = 0\n",
    "    global previous_state\n",
    "    previous_state = 0\n",
    "    global min_clients\n",
    "    min_clients = event_clients\n",
    "    \n",
    "    # Create local local variable used to store the result of state2_SL(), which needs to be used later on\n",
    "    result_state2 = None\n",
    "    \n",
    "    # With the obtained data, run the simulator for the desired single event\n",
    "    start = time.time()\n",
    "    \n",
    "    while state < 3:\n",
    "\n",
    "        if state == 0:        \n",
    "            result_state0 = state0_SL()\n",
    "\n",
    "        elif state == 1:\n",
    "            # If I got here from state0_SL()\n",
    "            if previous_state == 0:\n",
    "                result_state1 = state1_SL(result_state0[0], result_state0[1], result_state0[2])\n",
    "            \n",
    "            # If I got here from state1_SL()\n",
    "            elif previous_state == 1:\n",
    "                result_state1 = state1_SL(result_state1[0], result_state1[1], result_state1[2])\n",
    "\n",
    "        elif state == 2:\n",
    "            result_state2 = state2_SL(result_state1)\n",
    "\n",
    "    end = time.time()\n",
    "    runtime = end - start\n",
    "    \n",
    "    # Return a specific result depending on the final state at the end of the algorithm\n",
    "    if state == 3:\n",
    "        return [\"Success\", result_state2[0], result_state2[1], result_state2[2], runtime]\n",
    "    elif state == 4:\n",
    "        return [\"Unfeasible Type A\", None, None, None, runtime]\n",
    "    elif state == 5:\n",
    "        return [\"Unfeasible Type B\", None, None,None, runtime]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bbd70b7",
   "metadata": {},
   "source": [
    "## Each individual state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fef0071c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare our global variables first\n",
    "def state0_SL():\n",
    "    # Create our variables that will be passed from one state to another\n",
    "    paths = []\n",
    "    clients = []\n",
    "    servers = []\n",
    "    \n",
    "    # Create our global state and previous_state monitor variables\n",
    "    global state\n",
    "    state = 0\n",
    "    global previous_state\n",
    "    previous_state = 0\n",
    "    \n",
    "    # First we check which processors can work as servers and as clients\n",
    "    for processor in processors:\n",
    "        #If the processor can work as a server, then he can ALSO work as a potential client (M_server > M_client)\n",
    "        # Plus a heuristic just to stop at \"max_paths\" potential paths to calculate\n",
    "        if processor.residual >= (processor.M_server + total_batch_size) and len(servers) <= max_paths:\n",
    "            servers.append(processor)\n",
    "            clients.append(processor)\n",
    "        # If the processor can ONLY work as a client, then add him to the list of potential clients ONLY\n",
    "        # Plus the heuristic to limit the amount of potential clients to consider\n",
    "        elif processor.residual >= (processor.M_client + total_batch_size) and len(clients) <= max_paths:\n",
    "            clients.append(processor)\n",
    "    \n",
    "    # We will deal with the fact that a processor can be both in a later stage of the algorithm\n",
    "    \n",
    "    # If no servers exist, then we have to stop the program here\n",
    "    if len(servers) == 0:\n",
    "        # Finish the current state\n",
    "        previous_state = 0\n",
    "        # Go to state that adequately finishes the program\n",
    "        state = 4\n",
    "        return\n",
    "    \n",
    "    # If there aren't enough clients to the min_clients > len(clients), then end the program\n",
    "    elif len(clients) < min_clients:\n",
    "        # Finish the current state\n",
    "        previous_state = 0\n",
    "        # Go to state that adequately finishes the program\n",
    "        state = 5\n",
    "        return\n",
    "    \n",
    "    # We finished building the clients and servers list, so now we proceed to the next state\n",
    "    # Define the state that just finished!\n",
    "    previous_state = 0\n",
    "\n",
    "     # Define the next state!\n",
    "    state = 1\n",
    "    \n",
    "    return (clients, servers, paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75cb397a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def state1_SL(clients, servers, paths):\n",
    "    \n",
    "    global previous_state\n",
    "    global state\n",
    "    \n",
    "    # First copy the information from clients and servers onto a local list\n",
    "    local_clients = clients [:]\n",
    "    local_servers = servers [:]\n",
    "    \n",
    "    # Now we pick the first server from the list, and remove it from the servers list AND the clients list\n",
    "    # (IF it exists in the clients list of course)\n",
    "    current_server = local_servers[0]\n",
    "    local_servers.remove(current_server)\n",
    "    for client in local_clients:\n",
    "        if client.name == current_server.name:\n",
    "            local_clients.remove(current_server)\n",
    "    \n",
    "    # Now we will proceed to calculate all the vectors and matrices we need to make the paths later\n",
    "    T_client_serv = []\n",
    "    \n",
    "    # The following will be for the scaling factor to be used\n",
    "    total_client_D = 0\n",
    "    for client in local_clients:\n",
    "        total_client_D = total_client_D + client.D_client_in\n",
    "    \n",
    "    # Now we will calculate the full epoch (FP + BP) times for all client-current_server combos\n",
    "    for client in local_clients:\n",
    "        \n",
    "        # Obtain bandwidth (link) information\n",
    "        bandwidth_fetch = find_in_list(links, \"link_\" + str(client.ID) + str(client.ID)).value\n",
    "        bandwidth_server = find_in_list(links, \"link_\" + str(client.ID) + str(current_server.ID)).value\n",
    "                \n",
    "        # Calculate the client-server combo's respective T_fetch, T_procs, and T_transf\n",
    "        T_fetch = client.D_client_in / bandwidth_fetch\n",
    "        T_proc_client = client.G_client / client.power\n",
    "        T_proc_server = current_server.G_server / current_server.power\n",
    "        T_transf = client.D_client_out / bandwidth_server\n",
    "        \n",
    "        # Calculate the total T_client_serv for this specific client-server combo and log it\n",
    "        \n",
    "        # Both FP AND BP\n",
    "        T_client_serv_value = T_fetch + (1+1.5) * T_proc_client + (1+1.5) * T_proc_server + 2 * T_transf\n",
    "        \n",
    "        # Append\n",
    "        T_client_serv.append([client, current_server, T_client_serv_value])\n",
    "    \n",
    "    # Now we sort all the full epoch times from lowest (fastest) to highest (slowest)\n",
    "    sorted_T_client_serv = sorted(T_client_serv, key=lambda x: x[2])\n",
    "    \n",
    "    # Based on the minimum split required (== number of clients to use), obtain the necessary clients that have \n",
    "    # the fastest full epoch times for this client-current_server combo.\n",
    "    clients_to_use = []\n",
    "    for i in range(min_clients):\n",
    "        clients_to_use.append(sorted_T_client_serv[i])\n",
    "    \n",
    "    # Now using the chosen clients, we calculate the T_transf_weights between all of them. This is the time to \n",
    "    # pass the output weights between each other\n",
    "    T_transf_weights = 0\n",
    "    \n",
    "    # If we only need ONE client, the the time to transfer weights between clients is ZERO\n",
    "    if len(clients_to_use) == 1:\n",
    "        T_transf_weights = 0\n",
    "    # ELSE, we must consider the time it takes to transfer weights between clients and add those up \n",
    "    else:\n",
    "        for i in range(len(clients_to_use) - 1):\n",
    "            current_client = clients_to_use[i]\n",
    "            next_client = clients_to_use[i + 1]\n",
    "            current_client_ID = current_client[0].ID\n",
    "            next_client_ID = next_client[0].ID\n",
    "            T_transf_weights = ( T_transf_weights + \n",
    "                                ( current_client[0].D_weights / find_in_list(links, \"link_\" \n",
    "                                                                             + str(current_client_ID)\n",
    "                                                                             + str(next_client_ID)).value)\n",
    "                               )\n",
    "\n",
    "    # Now we have the fastest full epoch times for this client-current_server combo AND the total time it will\n",
    "    # take for the clients to pass the weights data to each other. So now we add everything together to obtain \n",
    "    # a final BEST full epoch training time for the chosen clients-current_server combo\n",
    "    \n",
    "    # First, the full epoch time for all the clients to use\n",
    "    total_full_epoch_time = 0\n",
    "    clients_to_use_names = []\n",
    "    for element in clients_to_use:\n",
    "        total_full_epoch_time = total_full_epoch_time + element[2]\n",
    "        # Also take advantage of this for loop to add all clients_to_use to a new list in an easier to read way\n",
    "        clients_to_use_names.append(element[0].name)\n",
    "    \n",
    "    # Finally, add both times up for the final training time for this path\n",
    "#     total_training_time = total_full_epoch_time  * batch_size * total_batches_SL + T_transf_weights\n",
    "    total_training_time = total_full_epoch_time * total_batches_SL + T_transf_weights\n",
    "    \n",
    "    # Add the current_path to paths. Additionally, the current total_training_time is in SECONDS, and considers\n",
    "    # only ONE epoch. We want it to consider ALL epochs defined in the config.ipynb file AND have its output\n",
    "    # be in HOURS, not seconds\n",
    "    current_path = [current_server.name, clients_to_use_names, (total_training_time * epochs) / time_factor]\n",
    "    paths.append(current_path)\n",
    "    \n",
    "    \n",
    "    # Now we have finalized the path using this current_server as the server. So, we also want to know the other\n",
    "    # potential paths starting from other servers. To do so, we remove the current_server from \"servers\", return\n",
    "    # the current result, and then start this state again with the new info!\n",
    "    \n",
    "    # Remove the current_server from the global servers list (the one given to this function at the beginning)\n",
    "    servers.remove(current_server)\n",
    "    \n",
    "    # Then we just start this state all over again until a path for all servers has been obtained!\n",
    "    if len(servers) > 0:\n",
    "        # First we finish the current state\n",
    "        previous_state = 1\n",
    "        # And move on to the next state (call this one again basically)\n",
    "        state = 1\n",
    "        return (clients, servers, paths)\n",
    "    else:\n",
    "        # Finish the current state\n",
    "        previous_state = 1\n",
    "        # And move on to the final state\n",
    "        state = 2\n",
    "        return paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b7e370a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def state2_SL(clients, aggregators, T_proc, T_transf, T_agg, paths):\n",
    "def state2_SL(paths):\n",
    "    \n",
    "    global previous_state\n",
    "    global state\n",
    "    \n",
    "    # This state is only in charge of obtaining the best path out of all the calculated paths so far\n",
    "    # Remember that:\n",
    "    # paths is a nested list of finalized individual paths\n",
    "    # and each individual path is a list containing [server, client list, train time]\n",
    "    \n",
    "    best_path = min(paths, key=itemgetter(2))\n",
    "            \n",
    "    # Program is done\n",
    "    previous_state = 2\n",
    "    state = 3\n",
    "    return (best_path) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
