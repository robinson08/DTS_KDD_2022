{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7aab7d0c",
   "metadata": {},
   "source": [
    "# Parallel Split Learning (PSL) Allocation Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d4e5b7",
   "metadata": {},
   "source": [
    "## The algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5bc1282",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reminder of what each state needs:\n",
    "# state0_PSL() needs () and returns (clients, servers, paths)\n",
    "# state1_PSL() needs (clients, servers, paths) and returns (paths)\n",
    "# OR (clients, servers, paths)\n",
    "# state2_PSL() needs (paths) and returns (best_path)\n",
    "\n",
    "def PSL_allocation_alg(event_processors, event_links, event_clients):\n",
    "    \n",
    "    # Set global variables so all states run correctly\n",
    "    global processors\n",
    "    processors = event_processors\n",
    "    global links\n",
    "    links = event_links\n",
    "    global state\n",
    "    state = 0\n",
    "    global previous_state\n",
    "    previous_state = 0\n",
    "    global min_clients\n",
    "    min_clients = event_clients\n",
    "    \n",
    "    # Create local local variable used to store the result of state2_PSL(), which needs to be used later on\n",
    "    result_state2 = None\n",
    "    \n",
    "    # With the obtained data, run the simulator for the desired single event\n",
    "    start = time.time()\n",
    "    \n",
    "    while state < 3:\n",
    "\n",
    "        if state == 0:        \n",
    "            result_state0 = state0_PSL()\n",
    "\n",
    "        elif state == 1:\n",
    "            # If I got here from state0_PSL()\n",
    "            if previous_state == 0:\n",
    "                result_state1 = state1_PSL(result_state0[0], result_state0[1], result_state0[2])\n",
    "            \n",
    "            # If I got here from state1_PSL()\n",
    "            elif previous_state == 1:\n",
    "                result_state1 = state1_PSL(result_state1[0], result_state1[1], result_state1[2])\n",
    "\n",
    "        elif state == 2:\n",
    "            result_state2 = state2_PSL(result_state1)\n",
    "\n",
    "    end = time.time()\n",
    "    runtime = end - start\n",
    "    \n",
    "    # Return a specific result depending on the final state at the end of the algorithm\n",
    "    if state == 3:\n",
    "        return [\"Success\", result_state2[0], result_state2[1], result_state2[2], runtime]\n",
    "    elif state == 4:\n",
    "        return [\"Unfeasible Type A\", None, None, None, runtime]\n",
    "    elif state == 5:\n",
    "        return [\"Unfeasible Type B\", None, None,None, runtime]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb4c184",
   "metadata": {},
   "source": [
    "## Each individual state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "381b4c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare our global variables first\n",
    "def state0_PSL():\n",
    "    # Create our variables that will be passed from one state to another\n",
    "    paths = []\n",
    "    clients = []\n",
    "    servers = []\n",
    "    \n",
    "    # Create our global state and previous_state monitor variables\n",
    "    global state\n",
    "    state = 0\n",
    "    global previous_state\n",
    "    previous_state = 0\n",
    "    \n",
    "    # First we check which processors can work as servers and as clients\n",
    "    for processor in processors:\n",
    "        #If the processor can work as a server, then he can ALSO work as a potential client (M_server > M_client)\n",
    "        # Plus a heuristic to not consider more than \"max_paths\" servers and starting points\n",
    "        if processor.residual >= (processor.M_server + total_batch_size) and len(servers) <= max_paths:\n",
    "            servers.append(processor)\n",
    "            clients.append(processor)\n",
    "        # If the processor can ONLY work as a client, then add him to the list of potential clients ONLY\n",
    "        # Plus a heuristic to limit the amount of potential clients to the first \"max_paths\" clients \n",
    "        # it can find that meet the memory constraint\n",
    "        elif processor.residual >= (processor.M_client + total_batch_size) and len(clients) <= max_paths:\n",
    "            clients.append(processor)\n",
    "    \n",
    "    # We will deal with the fact that a processor can be both in a later stage of the algorithm\n",
    "    \n",
    "    # If no servers exist, then we have to stop the program here\n",
    "    if len(servers) == 0:\n",
    "        # Finish the current state\n",
    "        previous_state = 0\n",
    "        # Go to state that adequately finishes the program\n",
    "        state = 4\n",
    "        return\n",
    "    \n",
    "    # If there aren't enough clients to the min_clients > len(clients), then end the program\n",
    "    elif len(clients) < min_clients:\n",
    "        # Finish the current state\n",
    "        previous_state = 0\n",
    "        # Go to state that adequately finishes the program\n",
    "        state = 5\n",
    "        return\n",
    "    \n",
    "    # We finished building the clients and servers list, so now we proceed to the next state\n",
    "    # Define the state that just finished!\n",
    "    previous_state = 0\n",
    "\n",
    "     # Define the next state!\n",
    "    state = 1\n",
    "    \n",
    "    return (clients, servers, paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29c48b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def state1_PSL(clients, servers, paths):\n",
    "    \n",
    "    global previous_state\n",
    "    global state\n",
    "    \n",
    "    # First copy the information from clients and servers onto a local list\n",
    "    local_clients = clients [:]\n",
    "    local_servers = servers [:]\n",
    "    \n",
    "    # Now we pick the first server from the list, and remove it from the servers list AND the clients list\n",
    "    # (IF it exists in the clients list of course)\n",
    "    current_server = local_servers[0]\n",
    "    local_servers.remove(current_server)\n",
    "    for client in local_clients:\n",
    "        if client.name == current_server.name:\n",
    "            local_clients.remove(current_server)\n",
    "    \n",
    "    # Now we will proceed to calculate all the vectors and matrices we need to make the paths later\n",
    "    T_client_serv = []\n",
    "    \n",
    "    # Now we will calculate the FP times for all possible client-current_server combos\n",
    "    for client in local_clients:\n",
    "        \n",
    "        # Obtain bandwidth (link) information\n",
    "        bandwidth_fetch = find_in_list(links, \"link_\" + str(client.ID) + str(client.ID)).value\n",
    "        bandwidth_server = find_in_list(links, \"link_\" + str(client.ID) + str(current_server.ID)).value\n",
    "                \n",
    "        # Calculate the client-server combo's respective T_fetch, T_procs, T_transf\n",
    "        T_fetch = client.D_client_in / bandwidth_fetch\n",
    "        T_proc_client = (client.G_client) / client.power\n",
    "        T_proc_server = (current_server.G_server) / current_server.power\n",
    "        T_transf = client.D_client_out / bandwidth_server\n",
    "        \n",
    "        # Calculate the total T_client_serv for this specific client-server combo and log it\n",
    "         \n",
    "        # FP only\n",
    "#         T_client_serv_value = T_fetch + T_proc_client + T_proc_server + T_transf\n",
    "        \n",
    "        # FP and BP. Remember that the FP + BP in the SERVER is SEQUENTIAL!! Only the client\n",
    "        # side is actually parallelized!\n",
    "        T_client_serv_value = T_fetch + (1+1.5) * T_proc_client + (1+1.5) * (min_clients) * T_proc_server + 2.0 * T_transf\n",
    "#         T_client_serv_value = T_fetch + (1+1.5) * T_proc_client + (1+1.5) * (min_clients) * T_proc_server + 2.0 * T_transf\n",
    "        # Append\n",
    "        T_client_serv.append([client, current_server, T_client_serv_value])\n",
    "    \n",
    "    # Now we sort all the FP times from lowest (fastest) to highest (slowest)\n",
    "    sorted_T_client_serv = sorted(T_client_serv, key=lambda x: x[2])\n",
    "    \n",
    "    # Based on the minimum split required (== number of clients to use), obtain the necessary clients that have \n",
    "    # the fastest full epoch times for this client-current_server combo.\n",
    "    clients_to_use = []\n",
    "    for i in range(min_clients):\n",
    "        clients_to_use.append(sorted_T_client_serv[i])\n",
    "\n",
    "    # I have now obtained all the best clients to use in this configuration. Now, the TOTAL training time for \n",
    "    # this system will be defined by our STRAGGLER, i.e., the slowest client in the system. By the time the \n",
    "    # slowest client is done, so will have all the others! Hence:    \n",
    "    # First, the full epoch time for all the clients to use\n",
    "#     total_full_epoch_time = max(clients_to_use, key = itemgetter(2))[2] * batch_size * total_batches_PSL\n",
    "    total_full_epoch_time = max(clients_to_use, key = itemgetter(2))[2] * total_batches_PSL\n",
    "#     total_full_epoch_time = 0\n",
    "    clients_to_use_names = []\n",
    "    for element in clients_to_use:\n",
    "#         total_full_epoch_time = total_full_epoch_time + element[2]\n",
    "        # Also take advantage of this for loop to add all clients_to_use to a new list in an easier to read way\n",
    "        clients_to_use_names.append(element[0].name)\n",
    "    \n",
    "    # Finally, add the necessary T_agg the server needs to do for the final training time for this path\n",
    "    # Remember we only aggregate ONCE per EPOCH! (One epoch contains all batches!)\n",
    "    T_agg = current_server.G_agg / current_server.power\n",
    "    total_training_time = total_full_epoch_time + T_agg \n",
    "    # Add the current_path to paths. Additionally, the current total_training_time is in SECONDS, and considers\n",
    "    # only ONE epoch. We want it to consider ALL epochs defined in the config.ipynb file AND have its output\n",
    "    # be in HOURS, not seconds\n",
    "    parall_factor_PSL = 0.85\n",
    "    current_path = [current_server.name, clients_to_use_names, (total_training_time * epochs * parall_factor_PSL) / time_factor]\n",
    "    paths.append(current_path)\n",
    "    \n",
    "    \n",
    "    # Now we have finalized the path using this current_server as the server. So, we also want to know the other\n",
    "    # potential paths starting from other servers. To do so, we remove the current_server from \"servers\", return\n",
    "    # the current result, and then start this state again with the new info!\n",
    "    \n",
    "    # Remove the current_server from the global servers list (the one given to this function at the beginning)\n",
    "    servers.remove(current_server)\n",
    "    \n",
    "    # Then we just start this state all over again until a path for all servers has been obtained!\n",
    "    if len(servers) > 0:\n",
    "        # First we finish the current state\n",
    "        previous_state = 1\n",
    "        # And move on to the next state (call this one again basically)\n",
    "        state = 1\n",
    "        return (clients, servers, paths)\n",
    "    else:\n",
    "        # Finish the current state\n",
    "        previous_state = 1\n",
    "        # And move on to the final state\n",
    "        state = 2\n",
    "        return paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be325ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def state2_PSL(clients, aggregators, T_proc, T_transf, T_agg, paths):\n",
    "def state2_PSL(paths):\n",
    "    \n",
    "    global previous_state\n",
    "    global state\n",
    "    \n",
    "    # This state is only in charge of obtaining the best path out of all the calculated paths so far\n",
    "    # Remember that:\n",
    "    # paths is a nested list of finalized individual paths\n",
    "    # and each individual path is a list containing [server, client list, train time]\n",
    "    \n",
    "    best_path = min(paths, key=itemgetter(2))\n",
    "            \n",
    "    # Program is done\n",
    "    previous_state = 2\n",
    "    state = 3\n",
    "    return (best_path) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
