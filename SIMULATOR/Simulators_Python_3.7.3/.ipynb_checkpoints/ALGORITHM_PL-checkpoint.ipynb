{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6238bd18",
   "metadata": {},
   "source": [
    "# Pipeline Learning (PL) Allocation Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eacf052",
   "metadata": {},
   "source": [
    "## The Algorithm Itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90609ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reminder of what each state needs:\n",
    "# state0_PL()\n",
    "# state1_PL(available_processors, current_layer, current_path, paths)\n",
    "# state2_PL(selected_processor, available_processors, current_layer, current_path, paths)\n",
    "# state3_PL(train_times, available_processors, current_layer, current_path, paths)\n",
    "# state4_PL(available_processors, current_layer, current_path, paths)\n",
    "def PL_allocation_alg(event_layers, event_processors, event_links, event_split):\n",
    "    \n",
    "    # Set global variables so all states run correctly\n",
    "    global layers\n",
    "    layers = event_layers\n",
    "    global processors\n",
    "    processors = event_processors\n",
    "    global links\n",
    "    links = event_links\n",
    "    global state\n",
    "    state = 0\n",
    "    global previous_state\n",
    "    previous_state = 0\n",
    "    global min_split\n",
    "    min_split = event_split\n",
    "    global needed_split\n",
    "    needed_split= event_split\n",
    "    \n",
    "    # Create local local variable used to store the result of state4_PL(), which needs to be used later on\n",
    "    result_state4 = None\n",
    "    \n",
    "    # With the obtained data, run the simulator for the desired single event\n",
    "    start = time.time()\n",
    "    \n",
    "    while state < 5:\n",
    "\n",
    "        if state == 0:        \n",
    "            result_state0 = state0_PL()\n",
    "\n",
    "        elif state == 1:        \n",
    "            # If I got here from state0_PL()\n",
    "            if previous_state == 0:\n",
    "                result_state1 = state1_PL(result_state0[0], result_state0[1], result_state0[2], \n",
    "                                       result_state0[3])\n",
    "\n",
    "            # If I got here from state3_PL()\n",
    "            elif previous_state == 3:\n",
    "                result_state1 = state1_PL(result_state3[0], result_state3[1], result_state3[2], \n",
    "                                   result_state3[3])\n",
    "\n",
    "        elif state == 2:\n",
    "            # If I got here from state1_PL()\n",
    "            if previous_state == 1:\n",
    "                result_state2 = state2_PL(result_state1[0], result_state1[1], result_state1[2], \n",
    "                               result_state1[3], result_state1[4])\n",
    "\n",
    "            # If I got here from state3_PL()\n",
    "            elif previous_state == 3:\n",
    "                result_state2 = state2_PL(result_state3[0], result_state3[1], result_state3[2], \n",
    "                               result_state3[3], result_state3[4])\n",
    "\n",
    "        elif state == 3:\n",
    "            # If I got here from state2_PL()\n",
    "            if previous_state == 2:\n",
    "                result_state3 = state3_PL(result_state2[0], result_state2[1], result_state2[2], result_state2[3], \n",
    "                                   result_state2[4])\n",
    "\n",
    "            # If I got here from state3_PL()\n",
    "            elif previous_state == 3:\n",
    "                result_state3 = state3_PL(result_state3[0], result_state3[1], result_state3[2], result_state3[3], \n",
    "                                   result_state3[4])\n",
    "\n",
    "        elif state == 4:\n",
    "            # If I got here from state1_PL()\n",
    "            if previous_state == 1:\n",
    "                result_state4 = state4_PL(result_state1[0], result_state1[1], result_state1[2], \n",
    "                               result_state1[3])\n",
    "\n",
    "            # If I got here from state3_PL()\n",
    "            elif previous_state == 3:\n",
    "                result_state4 = state4_PL(result_state3[0], result_state3[1], result_state3[2], \n",
    "                               result_state3[3])\n",
    "\n",
    "    end = time.time()\n",
    "    runtime = end - start\n",
    "    \n",
    "    # Return a specific result depending on the final state at the end of the algorithm\n",
    "    if state == 5:\n",
    "        return [\"Success\", result_state4[1], result_state4[2], runtime]\n",
    "    elif state == 6:\n",
    "        return [\"Unfeasible Type A\", None, None, runtime]\n",
    "    elif state == 7:\n",
    "        return [\"Unfeasible Type B\", None, None, runtime]\n",
    "    elif state == 8:\n",
    "        return [\"Unfeasible Type C\", None, None, runtime]\n",
    "    \n",
    "    # OR %%timeit for multiple runs of the algorithm and std dev and all the stuff\n",
    "    # OR %%time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10677fbc",
   "metadata": {},
   "source": [
    "## Each individual state_PL() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6033fe41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def state0_PL():\n",
    "    # Create our variables that will be passed from one state to another\n",
    "    current_layer = 0\n",
    "    current_path = []\n",
    "    paths = []\n",
    "    available_processors = []\n",
    "    \n",
    "    # Create our global state and previous_state monitor variables\n",
    "    global state\n",
    "    state = 0\n",
    "    global previous_state\n",
    "    previous_state = 0\n",
    "    \n",
    "    # Clean up the residual memory of all processors before starting\n",
    "    for processor in processors:    \n",
    "        processor.residual = processor.initial_residual\n",
    "        \n",
    "    # Reset the split variable before starting the algorithm\n",
    "    global needed_split\n",
    "    needed_split = min_split\n",
    "    \n",
    "    # If min_split > amount of layers in the NN then end the program:\n",
    "    if min_split > len(layers):\n",
    "        # End the program\n",
    "        state = 8\n",
    "        return\n",
    "    \n",
    "    # Start the algorithm by scanning for available processors for the current layer\n",
    "    # Plus a heuristic to only use \"max_paths\" potential processors of all the availabl ones\n",
    "    for j in range(len(processors)):\n",
    "        if processors[j].residual >= (layers[current_layer].memory + total_batch_size) and len(available_processors) < max_paths:\n",
    "            available_processors.append(processors[j])\n",
    "    \n",
    "    if len(available_processors) == 0:\n",
    "        # End the program\n",
    "        state = 6\n",
    "        \n",
    "        # Reset all processor residual memory\n",
    "        # Clean up the residual memory of all processors before finishing so it does not affect future \n",
    "        # algorithms that use this variable\n",
    "        for processor in processors:    \n",
    "            processor.residual = processor.initial_residual\n",
    "        return\n",
    "        \n",
    "    else:\n",
    "         # Define the state that just finished!\n",
    "        previous_state = 0\n",
    "        \n",
    "         # Define the next state!\n",
    "        state = 1\n",
    "        return (available_processors, current_layer, current_path, paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbf5bfc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def state1_PL(available_processors, current_layer, current_path, paths):\n",
    "    \n",
    "    global previous_state\n",
    "    global state\n",
    "    \n",
    "    # If for some reason we came back to this state AFTER at least ONE path was finished and we've gone through\n",
    "    # ALL possible available processors as starting points\n",
    "    if len(available_processors) == 0 and len(paths) != 0:\n",
    "        \n",
    "        # Define the state that just finished!\n",
    "        previous_state = 1\n",
    "        \n",
    "        # Just proceed to calculate the minimum path with the already available paths in the final list\n",
    "        state = 4\n",
    "        return (available_processors, current_layer, current_path, paths)\n",
    "    \n",
    "    # If we came back here after having tried ALL processors and ALL paths, AND not having found a viable path\n",
    "    # then end the program:\n",
    "    elif len(available_processors) == 0 and len(paths) == 0:\n",
    "        state = 7\n",
    "        \n",
    "        # Reset all processor residual memory\n",
    "        # Clean up the residual memory of all processors before finishing so it does not affect future \n",
    "        # algorithms that use this variable\n",
    "        for processor in processors:    \n",
    "            processor.residual = processor.initial_residual\n",
    "        \n",
    "        return\n",
    "        \n",
    "    # This is what will normally be done!\n",
    "    else:\n",
    "        \n",
    "        # Reset the available residual memory in all processors before proceeding, just in case we are\n",
    "        # coming back here from a failed path attempt\n",
    "        for processor in available_processors:    \n",
    "            processor.residual = processor.initial_residual\n",
    "        \n",
    "        # Reset the needed_split variable just in case we are coming back from a failed attempt\n",
    "        global needed_split\n",
    "        needed_split = min_split\n",
    "        \n",
    "        # Select the first processor from the list to start calculating the best path from there\n",
    "        selected_processor = available_processors[0]\n",
    "        selected_processor.residual = selected_processor.residual - layers[current_layer].memory - total_batch_size\n",
    "        \n",
    "        # Define the state that just finished!\n",
    "        previous_state = 1\n",
    "        \n",
    "        # Proceed to the next state\n",
    "        state = 2\n",
    "        return (selected_processor, available_processors, current_layer, current_path, paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c1b1bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def state2_PL(selected_processor, available_processors, current_layer, current_path, paths):\n",
    "    \n",
    "    global previous_state\n",
    "    global state\n",
    "    \n",
    "    # The currently selected processor is always given by the function calling this one!\n",
    "    \n",
    "    # Establish where the origin of the data for the current layer is coming from\n",
    "    if current_layer == 0:\n",
    "        # If I'm dealing with the first layer, I'm assuming the data will be fetched from that currently\n",
    "        # selected processor\n",
    "        origin_processor_ID = selected_processor.ID\n",
    "        \n",
    "    else:\n",
    "        # The PREVIOUS \"current\" processor is the CURRENT origin processor, so I take that info from the\n",
    "        # info appended to the \"current_path\" list\n",
    "        origin_processor_ID = current_path[-1][2]\n",
    "        \n",
    "    # Calculate all possible training times for the current layer running on the selected processor\n",
    "    train_times = []\n",
    "    \n",
    "    # Apply the heuristic \"max_paths\" here as well!\n",
    "    if len(processors) > max_paths:\n",
    "        for j in range(max_paths):\n",
    "\n",
    "            # Log the real training time of the current layer on the selected processor\n",
    "            # This one will only be used at the very end IF the current potential destination processor \n",
    "            # is chosen as the best destination\n",
    "            real_train_time = ( 1.0 * (layers[current_layer].fetch / \n",
    "                               (find_in_list(links, \"link_\" + \n",
    "                                            str(selected_processor.ID) + str(origin_processor_ID))).value) \n",
    "                               + (1+1.5) * (layers[current_layer].flops / processors[selected_processor.ID].power) \n",
    "                               + 1.0 * (layers[current_layer].write / (find_in_list(links, \"link_\" + \n",
    "                                                                              str(selected_processor.ID) + str(j))).value) \n",
    "                              )\n",
    "            # j here represents the processor I will be outputting to!\n",
    "\n",
    "            # Log the algorithm training time of the current layer on the selected processor\n",
    "            # This is used for the algorithm to make the decision of WHERE to process the next layer\n",
    "            if current_layer < (len(layers) - 1):\n",
    "                alg_train_time = (layers[current_layer].fetch / (find_in_list(links, \"link_\" + str(selected_processor.ID) + str(origin_processor_ID))).value) + (layers[current_layer].flops / processors[selected_processor.ID].power) + 2 * (layers[current_layer].write / (find_in_list(links, \"link_\" + \n",
    "                                            str(selected_processor.ID) + str(j))).value) + layers[current_layer + 1].flops / processors[j].power\n",
    "            else:\n",
    "                final_bandwidth = queue[0].links[0].value\n",
    "                alg_train_time = (layers[current_layer].fetch / (find_in_list(links, \"link_\" + str(selected_processor.ID) + str(origin_processor_ID))).value) + (layers[current_layer].flops / processors[selected_processor.ID].power) + (layers[current_layer].write / final_bandwidth)\n",
    "\n",
    "            # Append all the necessary info to a list to be accessed later\n",
    "            train_times.append([real_train_time, # For final training time calculation \n",
    "                                alg_train_time, # For algorithm destination processor selection\n",
    "                                processors[selected_processor.ID].ID, # To keep a log of the layer origin\n",
    "                                processors[j].ID]) # To log the layer destination for this potential selection\n",
    "    else:\n",
    "        for j in range(len(processors)):\n",
    "            # Log the real training time of the current layer on the selected processor\n",
    "            # This one will only be used at the very end IF the current potential destination processor \n",
    "            # is chosen as the best destination\n",
    "            real_train_time = ( 1.0 * (layers[current_layer].fetch / \n",
    "                               (find_in_list(links, \"link_\" + \n",
    "                                            str(selected_processor.ID) + str(origin_processor_ID))).value) \n",
    "                               + (1+1.5) * (layers[current_layer].flops / processors[selected_processor.ID].power) \n",
    "                               + 1.0 * (layers[current_layer].write / (find_in_list(links, \"link_\" + \n",
    "                                                                                  str(selected_processor.ID) + str(j))).value) \n",
    "                              )\n",
    "            # j here represents the processor I will be outputting to!\n",
    "\n",
    "            # Log the algorithm training time of the current layer on the selected processor\n",
    "            # This is used for the algorithm to make the decision of WHERE to process the next layer\n",
    "            if current_layer < (len(layers) - 1):\n",
    "                alg_train_time = (layers[current_layer].fetch / (find_in_list(links, \"link_\" + str(selected_processor.ID) + str(origin_processor_ID))).value) + (layers[current_layer].flops / processors[selected_processor.ID].power) + 2 * (layers[current_layer].write / (find_in_list(links, \"link_\" + \n",
    "                                            str(selected_processor.ID) + str(j))).value) + layers[current_layer + 1].flops / processors[j].power\n",
    "            else:\n",
    "                final_bandwidth = queue[0].links[0].value\n",
    "                alg_train_time = (layers[current_layer].fetch / (find_in_list(links, \"link_\" + str(selected_processor.ID) + str(origin_processor_ID))).value) + (layers[current_layer].flops / processors[selected_processor.ID].power) + (layers[current_layer].write / final_bandwidth)\n",
    "\n",
    "            # Append all the necessary info to a list to be accessed later\n",
    "            train_times.append([real_train_time, # For final training time calculation \n",
    "                                alg_train_time, # For algorithm destination processor selection\n",
    "                                processors[selected_processor.ID].ID, # To keep a log of the layer origin\n",
    "                                processors[j].ID]) # To log the layer destination for this potential selection\n",
    "\n",
    "    # Define the state that just finished!\n",
    "    previous_state = 2\n",
    "    \n",
    "    # Define the next state!\n",
    "    state = 3\n",
    "    return (train_times, available_processors, current_layer, current_path, paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1801823d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def state3_PL(train_times, available_processors, current_layer, current_path, paths):\n",
    "    \n",
    "    global previous_state\n",
    "    global state\n",
    "    \n",
    "    # Get the complete sublist which includes the minimum Algorithm Training Time (NOT the Real Training Time)\n",
    "    minimum_train_time = min(train_times, key=itemgetter(1))\n",
    "    \n",
    "    # Remember:\n",
    "    # minimum_train_time[0] -> used for final real training time calculation\n",
    "    # minimum_train_time[1] -> used for next layer selection\n",
    "    # minimum_train_time[2] -> to know where the current layer is being run at\n",
    "    # minimum_train_time[3] -> to know the current potential destination for the next layer\n",
    "    \n",
    "    if current_layer == len(layers) - 1:\n",
    "        \n",
    "        # This was the last layer, so we add it to the current_path and then add that current path to the bigger\n",
    "        # PATHS list\n",
    "        current_path.append(minimum_train_time)\n",
    "        paths.append(current_path)\n",
    "        \n",
    "        # Since we are done with this potential path, we remove the initial processor from the\n",
    "        # available_processors list, so that we can calculate a new path for the next processor in that list\n",
    "        available_processors.pop(0)\n",
    "        \n",
    "        # We also clean the \"current_path\" list for the future calculation\n",
    "        current_path = []\n",
    "        \n",
    "        if len(available_processors) > 0:\n",
    "            \n",
    "            # Define the state that just finished!\n",
    "            previous_state = 3\n",
    "            \n",
    "            # Loop back to state1 to calculate paths for the next processor in the list\n",
    "            current_layer = 0\n",
    "            state = 1\n",
    "            return (available_processors, current_layer, current_path, paths)\n",
    "        else: \n",
    "            \n",
    "            # Define the state that just finished!\n",
    "            previous_state = 3\n",
    "            \n",
    "            # No more available processors for layer0, so we proceed to the final best path calculation\n",
    "            state = 4\n",
    "            return (available_processors, current_layer, current_path, paths)\n",
    "        \n",
    "    elif processors[minimum_train_time[3]].residual >= layers[current_layer + 1].memory:\n",
    "        \n",
    "        # Potential destination CAN house the next layer, so we add it to the current path\n",
    "        current_path.append(minimum_train_time)\n",
    "        \n",
    "        # Create an easier to read current_path which only includes ints because I will use the set() method\n",
    "        # later to identify how many unique processors I have in my current path so far. This is because I need\n",
    "        # to apply the minimum_split constraint!\n",
    "        current_path_easy_read = []\n",
    "        for selection in current_path:\n",
    "            current_path_easy_read.append(selection[2])\n",
    "        \n",
    "        # Check if we need to perform the split now. If we DO, then make the current processor's residual = 0\n",
    "        # to force the algorithm to change processors. If NOT, then we proceed as normal\n",
    "        global needed_split        \n",
    "        if len(current_path_easy_read) >= int((len(layers) / needed_split)) and len(set(current_path_easy_read)) <= min_split and needed_split > 0:\n",
    "                processors[minimum_train_time[3]].residual = 0\n",
    "                needed_split = needed_split - 1\n",
    "        else:\n",
    "            # Update the residual memory of the processor, now that we know it will be part of our path\n",
    "            processors[minimum_train_time[3]].residual = processors[minimum_train_time[3]].residual - layers[current_layer + 1].memory\n",
    "        \n",
    "        # Progress on to the next layer\n",
    "        current_layer = current_layer + 1\n",
    "        \n",
    "        # Define the state that just finished!\n",
    "        previous_state = 3\n",
    "        \n",
    "        # Establish the \"current\" processor for the next calc. The \"current\" processor for the NEXT calc is\n",
    "        # this current calc's destination\n",
    "        state = 2\n",
    "        return (processors[minimum_train_time[3]], available_processors, current_layer, current_path, paths)\n",
    "    \n",
    "    else: \n",
    "        # The processor that led to THIS min(train_times) is not capable of housing the next layer\n",
    "        # So we must remove this train_time from the list and choose another new minimum. Then try again\n",
    "        train_times.remove(minimum_train_time)\n",
    "        \n",
    "        # If it happens that we've already deleted all train_time paths, then that means that we must choose a new\n",
    "        # direction all together, because after the current layer, NO OTHER PROCESSOR can house the next layer\n",
    "        if len(train_times) < 1:\n",
    "            \n",
    "            # It's safe to remove specifically the first element from the list because we always choose\n",
    "            # the first one in state1_PL()\n",
    "            available_processors.pop(0)\n",
    "            \n",
    "            # Define the state that just finished!\n",
    "            previous_state = 3\n",
    "            \n",
    "            # Go back to state1_PL() and choose a different available processor to create a path again\n",
    "            current_path = []\n",
    "            current_layer = 0\n",
    "            state = 1\n",
    "            return (available_processors, current_layer, current_path, paths)\n",
    "        \n",
    "        else:\n",
    "            # Define the state that just finished!\n",
    "            previous_state = 3\n",
    "            \n",
    "            # Normally we will just try this state again!\n",
    "            state = 3\n",
    "            return (train_times, available_processors, current_layer, current_path, paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48f1d306",
   "metadata": {},
   "outputs": [],
   "source": [
    "def state4_PL(available_processors, current_layer, current_path, paths):\n",
    "    \n",
    "    global previous_state\n",
    "    global state \n",
    "    \n",
    "    # Remember that:\n",
    "    # paths is a list of finalized current_path's\n",
    "    # and each current_path is a list containing [real train time, alg train time, origin, dest]\n",
    "    \n",
    "    path_totals = []\n",
    "    for path in paths:\n",
    "        \n",
    "        # Each \"path\" here is a list of [T_real1, T_alg1, origin1, dest1]\n",
    "        path_value = 0\n",
    "        \n",
    "        for selection in path:\n",
    "            # Add the real training time from each processor selection in each path to the path value\n",
    "            path_value = path_value + selection[0]\n",
    "        \n",
    "        # After all Treal's have been added up, we add that path_value to the path_totals list\n",
    "        path_totals.append(path_value)\n",
    "    \n",
    "    # After all path values have been totaled, we choose the path with the minimum path value\n",
    "    best_path_index = path_totals.index(min(path_totals))\n",
    "    best_path_value = min(path_totals)\n",
    "    best_path = paths[best_path_index]\n",
    "    \n",
    "    # Let's obtain the best path route for easier reading\n",
    "    best_path_route = []\n",
    "    for selection in best_path:\n",
    "        best_path_route.append(selection[2])\n",
    "            \n",
    "    # Program is done\n",
    "    state = 5\n",
    "    \n",
    "    # Reset all processor residual memory\n",
    "    # Clean up the residual memory of all processors before finishing so it does not affect future \n",
    "    # algorithms that use this variable\n",
    "    for processor in processors:    \n",
    "        processor.residual = processor.initial_residual\n",
    "    \n",
    "    # The best_path_value is currently in seconds and only considers ONE epoch, so we overwrite it to consider\n",
    "    # the \"epochs\" variable defined in config.ipynb AND have its unit be HOURS, not seconds\n",
    "#     return (state, best_path_route, (best_path_value * epochs * batch_size * total_batches_PL) / time_factor)\n",
    "    return (state, best_path_route, (best_path_value * epochs * total_batches_PL) / time_factor)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
