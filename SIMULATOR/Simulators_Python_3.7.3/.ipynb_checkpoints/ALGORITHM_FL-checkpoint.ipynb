{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ae3dcdb",
   "metadata": {},
   "source": [
    "# Federated Learning (FL) Allocation Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3eec64a",
   "metadata": {},
   "source": [
    "## The Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f251a15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reminder of what each state needs:\n",
    "# state0_FL() needs () and returns (clients, aggregators, T_proc, T_transf, T_agg, paths)\n",
    "# state1_FL() needs (clients, aggregators, T_proc, T_transf, T_agg, paths) and returns (paths)\n",
    "# OR (clients, aggregators, T_proc, T_transf, T_agg, paths)\n",
    "# state2_FL() needs (paths) and returns (best_path)\n",
    "\n",
    "def FL_allocation_alg(event_processors, event_links, event_clients):\n",
    "    \n",
    "    # Set global variables so all states run correctly\n",
    "    global processors\n",
    "    processors = event_processors\n",
    "    global links\n",
    "    links = event_links\n",
    "    global state\n",
    "    state = 0\n",
    "    global previous_state\n",
    "    previous_state = 0\n",
    "    global min_clients\n",
    "    min_clients = event_clients\n",
    "    \n",
    "    # Create local local variable used to store the result of state2_FL(), which needs to be used later on\n",
    "    result_state2 = None\n",
    "    \n",
    "    # With the obtained data, run the simulator for the desired single event\n",
    "    start = time.time()\n",
    "    \n",
    "    while state < 3:\n",
    "\n",
    "        if state == 0:        \n",
    "            result_state0 = state0_FL()\n",
    "\n",
    "        elif state == 1:\n",
    "            # If I got here from state0_FL()\n",
    "            if previous_state == 0:\n",
    "                result_state1 = state1_FL(result_state0[0], result_state0[1], result_state0[2], \n",
    "                                       result_state0[3], result_state0[4], result_state0[5])\n",
    "            \n",
    "            # If I got here from state1_FL()\n",
    "            elif previous_state == 1:\n",
    "                result_state1 = state1_FL(result_state1[0], result_state1[1], result_state1[2], \n",
    "                                       result_state1[3], result_state1[4], result_state1[5])\n",
    "\n",
    "        elif state == 2:\n",
    "            result_state2 = state2_FL(result_state1)\n",
    "\n",
    "    end = time.time()\n",
    "    runtime = end - start\n",
    "    \n",
    "    # Return a specific result depending on the final state at the end of the algorithm\n",
    "    if state == 3:\n",
    "        return [\"Success\", result_state2[0], result_state2[1], result_state2[2], runtime]\n",
    "    elif state == 4:\n",
    "        return [\"Unfeasible Type A\", None, None, None, runtime]\n",
    "    elif state == 5:\n",
    "        return [\"Unfeasible Type B\", None, None,None, runtime]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7530e4f",
   "metadata": {},
   "source": [
    "## Each individual state_FL() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da25a4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare our global variables first\n",
    "def state0_FL():\n",
    "    # Create our variables that will be passed from one state to another\n",
    "    paths = []\n",
    "    clients = []\n",
    "    aggregators = []\n",
    "    T_proc = []\n",
    "    T_transf = []\n",
    "    T_agg = []\n",
    "    \n",
    "    # Create our global state and previous_state monitor variables\n",
    "    global state\n",
    "    state = 0\n",
    "    global previous_state\n",
    "    previous_state = 0\n",
    "    \n",
    "    # First we check which processors can house the current NN with the amount of data they want to run\n",
    "    # The bigger the data they want to train the NN with, the more memory they will need to house it\n",
    "    for processor in processors:\n",
    "        #If the client can house the NN, then it CAN be considered a viable client\n",
    "        # Plus a heuristic to only consider \"max_paths\" clients\n",
    "        if processor.residual >= (processor.M_base + total_batch_size) and len(clients) <= max_paths:\n",
    "            clients.append(processor)\n",
    "        # If the client CANNOT house its own NN, then it can only be considered as an Aggregator. This will only\n",
    "        # add a max of \"max_paths\" aggregators to the list, to limit the processing time of the algorithm\n",
    "        # Additionally, a processor can only be an aggregator if it has the memory to house all the weights\n",
    "        elif processor.residual >= processor.M_agg and len(aggregators) <= max_paths:\n",
    "            aggregators.append(processor)\n",
    "    \n",
    "    # The sign \"<=\" is correct, because ONE of these processors might be chosen later on as the aggregator. Hence,\n",
    "    # we would still need at least a \"max_paths\" number of processors in the list to be able to build the whole \n",
    "    # distributed training topology\n",
    "    \n",
    "    # If no clients exist, then we have to stop the program here\n",
    "    if len(clients) == 0:\n",
    "        # Finish the current state\n",
    "        previous_state = 0\n",
    "        # Go to state that adequately finishes the program\n",
    "        state = 4\n",
    "        return\n",
    "    \n",
    "    # If the min_clients > len(clients), then end the program\n",
    "    elif len(clients) < min_clients:\n",
    "        # Finish the current state\n",
    "        previous_state = 0\n",
    "        # Go to state that adequately finishes the program\n",
    "        state = 5\n",
    "        return\n",
    "    \n",
    "    # If no aggregators exist, then that means that every client can actually house its own NN\n",
    "    # In this case, we have no preferences for which processor should be the aggregator, so we just make them\n",
    "    # all potential candidates. Also include a heuristic to limit it to \"max_paths\" potential aggregators\n",
    "    if len(aggregators) == 0:\n",
    "        aggregators = processors [:max_paths]\n",
    "    # The [:] here is because I want the COPY of processors to be called \"aggregators\", NOT for aggregators to \n",
    "    # be another reference/name for processors!!\n",
    "    \n",
    "    # Now we can calculate the time it would take for each client to FETCH the data AND PROCESS its NN\n",
    "    # AND the time it would take for each client to process the aggregation phase\n",
    "    for client in clients:\n",
    "        T_proc.append([client, (1 + 1.5) * (client.G_whole / client.power) \n",
    "                       + client.D_client_in / (find_in_list(links, \"link_\" + str(client.ID) \n",
    "                                                            + str(client.ID)).value)])\n",
    "        \n",
    "        T_agg.append([client, client.G_agg / client.power])\n",
    "    # Remember that G_agg is the same for all processors, since whoever ends up being the\n",
    "    # Aggregator will always need to do the same simple operation: average the weights\n",
    "    \n",
    "    # The size of the weights-only output for all G's is the same because the NN is the same\n",
    "    # The time it takes to PROCESS the NN will depend on many factors, but the weights-only output stays the same\n",
    "    # Hence, we now calculate T_transf with D_weights and the info in the links list\n",
    "    D_weights = clients[0].D_weights # Just take any D_weights from any processor, since it's the same for all\n",
    "    for link in links:\n",
    "        T_transf.append([link, 2.0 * (D_weights / link.value)])\n",
    "        \n",
    "    else:\n",
    "         # Define the state that just finished!\n",
    "        previous_state = 0\n",
    "        \n",
    "         # Define the next state!\n",
    "        state = 1\n",
    "        return (clients, aggregators, T_proc, T_transf, T_agg, paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c43aa1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def state1_FL(clients, aggregators, T_proc, T_transf, T_agg, paths):\n",
    "\n",
    "    global previous_state\n",
    "    global state\n",
    "    \n",
    "    # Create our T_train where two \"best\" paths will be added:\n",
    "    # 1. One \"best\" path based on which clients can process the NN the fastest\n",
    "    # 2. Another \"best\" path based on which clients have the fastest bandwidth between client and aggregator\n",
    "    # This way the \"final\" selected path for the event will be able to counter the main system bottleneck:\n",
    "    # bandwidth or processing power, and choose the best training time for the currently available system\n",
    "    \n",
    "    T_train = []\n",
    "    \n",
    "    # Choose our first potential aggregator\n",
    "    current_aggregator = aggregators[0]\n",
    "    \n",
    "    # Create a new variable to NOT modify the original T_proc. Hence I HAVE to use the [:] at the end to create\n",
    "    # a COPY, and not just a new REFERENCE to T_proc\n",
    "    local_T_proc = T_proc[:]\n",
    "    \n",
    "    # Remove all instances of this aggregator in local_T_proc (will usually only be one)\n",
    "    for element in T_proc:\n",
    "        if element[0].name == current_aggregator.name:\n",
    "            local_T_proc.remove(element)\n",
    "            \n",
    "    # Create a new variable to NOT modify the original T_transf. Same case as with T_proc\n",
    "    local_T_transf = T_transf[:]    \n",
    "    \n",
    "    # Now I will modify T_transf so that only the transfer times between clients and my \n",
    "    # current aggregator are considered. In other words, all values where the ORIGIN of the link is the\n",
    "    # current_aggregator will be removed, to only consider those links FROM clients TO aggregator\n",
    "    \n",
    "    # If the dest of the link is NOT the current aggregator...\n",
    "    # ...OR the origin and dest are the same...\n",
    "    # OR the origin is the aggregator, then REMOVE that link from local_T_transf\n",
    "    links_to_remove = []\n",
    "    # Look for the links to remove first\n",
    "    for link in local_T_transf:\n",
    "        if ( link[0].dest != current_aggregator.ID \n",
    "            or link[0].dest == link[0].origin \n",
    "            or link[0].origin == current_aggregator.ID ):\n",
    "            links_to_remove.append(link)\n",
    "    # Then remove them\n",
    "    for link in links_to_remove:\n",
    "        local_T_transf.remove(link)\n",
    "            \n",
    "    ############################################################################################################\n",
    "    # First we will calculate the best training time based only on which clients process the NN the fastest\n",
    "    \n",
    "    # Now I will reorganize T_proc from fastest processing time to slowest processing time\n",
    "    # Remember that T_proc = [client, client.flops / client.power]\n",
    "    sorted_T_proc = sorted(local_T_proc, key=lambda x: x[1])\n",
    "    \n",
    "    # Now I will calculate the Training Time based on the fastest processors\n",
    "    # First, get all the T_procs I need to sum, based on how many clients I want (defined by min_clients)\n",
    "    # And do the same with the T_transf\n",
    "    T_proc_to_sum = []\n",
    "    T_transf_to_sum = []\n",
    "    \n",
    "    # If we don't have enough clients, then send an error code\n",
    "    if len(sorted_T_proc) < min_clients:\n",
    "        # Finish the current state\n",
    "        previous_state = 0\n",
    "        # Go to state that adequately finishes the program\n",
    "        state = 5\n",
    "        return\n",
    "    \n",
    "    for i in range(min_clients):\n",
    "        T_proc_to_sum.append(sorted_T_proc[i]) \n",
    "        for element in local_T_transf:\n",
    "            if element[0].origin == T_proc_to_sum[i][0].ID and element[0].dest == current_aggregator.ID:\n",
    "                T_transf_to_sum.append(element)\n",
    "    \n",
    "    # Now to the calculation for the best T_train based on highest processing power!\n",
    "#     T_train_pow = (current_aggregator.G_agg / current_aggregator.power\n",
    "#                    + sum(i[1] for i in T_proc_to_sum) \n",
    "#                    + sum(i[1] for i in T_transf_to_sum))\n",
    "#     T_train_pow = (current_aggregator.G_agg / current_aggregator.power\n",
    "#                    + sum(i[1] for i in T_proc_to_sum) \n",
    "#                    + sum(i[1] for i in T_transf_to_sum))\n",
    "    \n",
    "    # Remember that I don't have to add ALL of the times, because everything is happening in PARALLEL! If I added\n",
    "    # all of the times one after the other, then it would essentially be a sequential algorithm!! By the time the\n",
    "    # BIGGEST time (slowest client) is done, THAT is when everyone is done!\n",
    "#     T_train_pow = (current_aggregator.G_agg / current_aggregator.power\n",
    "#                     + max(T_proc_to_sum, key = itemgetter(1))[1] * epochs * batch_size * total_batches_FL\n",
    "#                     + max(T_transf_to_sum, key = itemgetter(1))[1] * epochs * batch_size * total_batches_FL\n",
    "#                   )\n",
    "#     T_train_pow = (current_aggregator.G_agg / current_aggregator.power\n",
    "#                     + max(T_proc_to_sum, key = itemgetter(1))[1] * epochs * total_batches_FL\n",
    "#                     + max(T_transf_to_sum, key = itemgetter(1))[1] * epochs * total_batches_FL\n",
    "#                   )\n",
    "    T_train_pow = (current_aggregator.G_agg / current_aggregator.power\n",
    "                    + max(T_proc_to_sum, key = itemgetter(1))[1] * total_batches_FL\n",
    "                    + max(T_transf_to_sum, key = itemgetter(1))[1]\n",
    "                  )\n",
    "    \n",
    "    # Create list of clients used in thise addition\n",
    "    clients_pow = []\n",
    "    for element in T_proc_to_sum:\n",
    "        clients_pow.append(element[0].name)\n",
    "    \n",
    "    # Add it to the current T_train. T_train_pow is currently in SECONDS and considers only ONE epoch. Hence, \n",
    "    # we want the total train time to consider all \"epochs\" defined in config.ipynb AND have its output be in \n",
    "    # HOURS, not seconds\n",
    "#     T_train.append([current_aggregator.name, clients_pow, (T_train_pow * epochs * correction_factor_parall) / time_factor])\n",
    "    T_train.append([current_aggregator.name, clients_pow, (T_train_pow * epochs) / time_factor])\n",
    "    \n",
    "    ############################################################################################################\n",
    "    # Second we will calculate the best training time based only on which LINKS between clients and aggregator\n",
    "    # are the fastest\n",
    "    \n",
    "    # First we reorganize T_transf from fastest link to slowest link\n",
    "    # Remember that T_transf = [link, (D_weights / link.value)]\n",
    "    sorted_T_transf = sorted(local_T_transf, key=lambda x: x[1])\n",
    "    \n",
    "    # Do the same process as before to idenfity which T_procs and T_transfs I need to sum\n",
    "    T_proc_to_sum = []\n",
    "    T_transf_to_sum = []\n",
    "    \n",
    "    # If we don't have enough clients, then send an error code\n",
    "    if len(sorted_T_proc) < min_clients:\n",
    "        # Finish the current state\n",
    "        previous_state = 0\n",
    "        # Go to state that adequately finishes the program\n",
    "        state = 5\n",
    "        return\n",
    "    \n",
    "    for i in range(min_clients):\n",
    "        T_transf_to_sum.append(sorted_T_transf[i])\n",
    "        for element in local_T_proc:\n",
    "            if element[0].ID == T_transf_to_sum[i][0].origin:\n",
    "                T_proc_to_sum.append(element)\n",
    "    \n",
    "    # Now to the calculation for the best T_train based on highest BANDWIDTH!\n",
    "#     T_train_link = (current_aggregator.G_agg / current_aggregator.power\n",
    "#                     + sum(i[1] for i in T_proc_to_sum) \n",
    "#                     + sum(i[1] for i in T_transf_to_sum))\n",
    "    \n",
    "    # Remember that I don't have to add ALL of the times, because everything is happening in PARALLEL! If I added\n",
    "    # all of the times one after the other, then it would essentially be a sequential algorithm!! By the time the\n",
    "    # BIGGEST time (slowest client) is done, THAT is when everyone is done!\n",
    "#     T_train_link = (current_aggregator.G_agg / current_aggregator.power\n",
    "#                     + max(T_proc_to_sum, key = itemgetter(1))[1] * batch_size * total_batches_FL\n",
    "#                     + max(T_transf_to_sum, key = itemgetter(1))[1] * batch_size * total_batches_FL\n",
    "#                    )\n",
    "    T_train_link = (current_aggregator.G_agg / current_aggregator.power\n",
    "                    + max(T_proc_to_sum, key = itemgetter(1))[1] * total_batches_FL\n",
    "                    + max(T_transf_to_sum, key = itemgetter(1))[1]\n",
    "                   )\n",
    "    \n",
    "    # Create list of clients used in thise addition\n",
    "    clients_link = []\n",
    "    for element in T_transf_to_sum:\n",
    "        clients_link.append(\"processor_\" + str(element[0].origin))\n",
    "    \n",
    "    # Add it to the current T_train. T_train_link is currently in SECONDS and considers only ONE epoch. Hence, \n",
    "    # we want the total train time to consider all \"epochs\" defined in config.ipynb AND have its output be in \n",
    "    # HOURS, not seconds\n",
    "    T_train.append([current_aggregator.name, clients_link, (T_train_link * epochs) / time_factor])\n",
    "    \n",
    "    \n",
    "    ############################################################################################################\n",
    "    # Third, we only care about the fastest path, so we will only choose ONE of the two available paths\n",
    "    minimum_train_time = min(T_train, key=itemgetter(2))\n",
    "    \n",
    "    ############################################################################################################\n",
    "    # Fourth, append the path to the paths list\n",
    "    paths.append(minimum_train_time)\n",
    "    \n",
    "    # Up to this point, we have determined the best path, whether it be based on processor power or on available\n",
    "    # bandwidth, from one of the potential aggregators. Now we must go back and repeat this with ALL other\n",
    "    # potential aggregators from our original list of aggregators\n",
    "    # To do so, we first remove our current aggregator from the aggregator list:\n",
    "    aggregators.remove(current_aggregator)\n",
    "    \n",
    "    # Then we just start this state all over again until a path for all aggregators has been reached\n",
    "    if len(aggregators) > 0:\n",
    "        # First we finish the current state\n",
    "        previous_state = 1\n",
    "        # And move on to the next state\n",
    "        state = 1\n",
    "        return (clients, aggregators, T_proc, T_transf, T_agg, paths)\n",
    "    else:\n",
    "        # Finish the current state\n",
    "        previous_state = 1\n",
    "        # And move on to the final state\n",
    "        state = 2\n",
    "        return paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7b6a087",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def state2_FL(clients, aggregators, T_proc, T_transf, T_agg, paths):\n",
    "def state2_FL(paths):\n",
    "    \n",
    "    global previous_state\n",
    "    global state\n",
    "    \n",
    "    # This state is only in charge of obtaining the best path out of all the calculated paths so far\n",
    "    # Remember that:\n",
    "    # paths is a nested list of finalized individual paths\n",
    "    # and each individual path is a list containing [aggregator, client list, train time]\n",
    "    \n",
    "    best_path = min(paths, key=itemgetter(2))\n",
    "            \n",
    "    # Program is done\n",
    "    previous_state = 2\n",
    "    state = 3\n",
    "    return (best_path) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
